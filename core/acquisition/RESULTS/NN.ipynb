{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hpolib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2702bb428b87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhpolib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmarks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconv_net\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConvolutionalNeuralNetworkOnCIFAR10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'hpolib'"
     ]
    }
   ],
   "source": [
    "from hpolib.benchmarks.ml import conv_net\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "b = conv_net.ConvolutionalNeuralNetworkOnCIFAR10()\n",
    "stop = time.time()\n",
    "print(\"data import time: \",stop-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.9\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.2497 - accuracy: 0.9242 - val_loss: 0.1142 - val_accuracy: 0.9656\n",
      "Test loss: 0.11417827072292566\n",
      "Test accuracy: 0.9656\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 1\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import time\n",
    "\n",
    "class mnist_mlp():\n",
    "    def __init__(self,max_time=2e-2):\n",
    "        self.batch_size = 128\n",
    "        self.learning_rate = 0.001\n",
    "        self.rho = 0.9\n",
    "        self.epsilon=1e-07\n",
    "        self.epochs = 3\n",
    "        self.samples = 2\n",
    "        self.max_time = max_time\n",
    "        \n",
    "    def train_model(self,X,verbose=0):\n",
    "        \"\"\"\n",
    "        Load Mnist data, creates a nueral network, create an\n",
    "        optimizer, put all three together and train. Finally\n",
    "        perform test and return test error.\n",
    "        \"\"\"\n",
    "        batch_size = self.batch_size\n",
    "        learning_rate = self.learning_rate\n",
    "        rho = self.rho\n",
    "        epsilon = self.epsilon\n",
    "        epochs = self.epochs\n",
    "        \n",
    "        if len(X.shape) == 1:\n",
    "            X = np.array(X).reshape(1,-1)\n",
    "       \n",
    "        validation_score = np.zeros((X.shape[0],1))\n",
    "       \n",
    "        for index in range(X.shape[0]):\n",
    "            x = X[index]\n",
    "            x = np.array(x).reshape(-1)\n",
    "            x = x.reshape(1,-1)\n",
    "            print(\"x\",x[:,0][0],x[:,1][0], x[:,2][0], x[:,3][0])\n",
    "            # Part 1: get the dataset\n",
    "            (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "            x_train = x_train.reshape(60000, 784)\n",
    "            x_test = x_test.reshape(10000, 784)\n",
    "            self.x_test = x_test\n",
    "            x_train = x_train.astype('float32')\n",
    "            x_test = x_test.astype('float32')\n",
    "            x_train /= 255\n",
    "            x_test /= 255\n",
    "            y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "            y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "            # Part 2: Make model\n",
    "            print(int(x[:,2][0]),x[:,0][0],int(x[:,3][0]), x[:,1][0] )\n",
    "            model = Sequential()\n",
    "            model.add(Dense(int(np.power(2,x[:,2][0])), activation='relu', input_shape=(784,)))\n",
    "            model.add(Dropout(x[:,0][0]))\n",
    "            model.add(Dense(int(np.power(2,x[:,3][0])), activation='relu'))\n",
    "            model.add(Dropout(x[:,1][0]))\n",
    "            model.add(Dense(num_classes, activation='softmax'))\n",
    "            if verbose==1: model.summary()\n",
    "\n",
    "            # Part 3: Make optimizer\n",
    "            optimizer = tf.keras.optimizers.RMSprop(lr=learning_rate,rho=rho,epsilon=epsilon)\n",
    "\n",
    "               # Part 4: compile\n",
    "            model.compile(loss='categorical_crossentropy',\n",
    "                          optimizer=optimizer,\n",
    "                          metrics=['accuracy'])\n",
    "\n",
    "            # Part 5: train\n",
    "            print(\"batch_size\",batch_size,\"epochs\",epochs)\n",
    "            history = model.fit(x_train, y_train,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=epochs,\n",
    "                            verbose=verbose,\n",
    "                            validation_data=(x_test, y_test))\n",
    "            \n",
    "            self.model=model\n",
    "            # Part 6: get test measurements\n",
    "            score = model.evaluate(x_test, y_test, verbose=1)\n",
    "            validation_score[index,0] = score[0]\n",
    "        \n",
    "        \n",
    "        return validation_score # test classification error\n",
    "\n",
    "\n",
    "    def prediction_time(self,X,verbose=0):\n",
    "        \n",
    "        batch_size = self.batch_size\n",
    "        learning_rate = self.learning_rate\n",
    "        rho = self.rho\n",
    "        epsilon = self.epsilon\n",
    "        epochs = self.epochs\n",
    "        \n",
    "        if len(X.shape) == 1:\n",
    "            X = np.array(X).reshape(1,-1)\n",
    "       \n",
    "        X_mean_average = np.zeros((X.shape[0],1))\n",
    "        for index in range(X.shape[0]):\n",
    "            \n",
    "            x = X[index]\n",
    "            \n",
    "            self.train_model(x, verbose)\n",
    "            \n",
    "            samples = self.samples\n",
    "            average_time =np.zeros(samples)\n",
    "            for i in range(samples):\n",
    "                start = time.time()\n",
    "                self.model.predict_classes(x = self.x_test,batch_size=batch_size)\n",
    "                stop = time.time()\n",
    "                average_time[i] = stop - start\n",
    "            \n",
    "            print(\"np.mean(average_time)\",np.mean(average_time))\n",
    "            print(\"std\", np.std(average_time))\n",
    "            print(\"mse\", np.std(average_time)/np.sqrt(len(average_time)))\n",
    "        X_mean_average[index,0] = np.mean(average_time) \n",
    "        return X_mean_average\n",
    "        \n",
    "objective_function = mnist_mlp()\n",
    "\n",
    "# print(\"Verbose execution\")\n",
    "# test_error = objective_function.train_model(X = np.array([0.2,0.2,10,10]))\n",
    "# print(\"Test error:\", test_error)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x 0.2 0.2 9.0 9.0\n",
      "9 0.2 9 0.2\n",
      "batch_size 128 epochs 3\n",
      "10000/10000 [==============================] - 0s 37us/sample - loss: 0.0886 - accuracy: 0.9748\n",
      "np.mean(average_time) 0.1356058120727539\n",
      "std 0.021286725997924805\n",
      "mse 0.015051988302392606\n"
     ]
    }
   ],
   "source": [
    "test_error = objective_function.prediction_time(X = np.array([0.2,0.2,9,9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x 0.2 0.2 5.0 5.0\n",
      "5 0.2 5 0.2\n",
      "batch_size 128 epochs 3\n",
      "10000/10000 [==============================] - 0s 20us/sample - loss: 0.1913 - accuracy: 0.9432\n",
      "np.mean(average_time) 0.05908608436584473\n",
      "std 0.02191901206970215\n",
      "mse 0.015499082071396171\n"
     ]
    }
   ],
   "source": [
    "test_error = objective_function.prediction_time(X = np.array([0.2,0.2,5,5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[5, 12],  # n_units_1\n",
    "[5, 12],  # n_units_2\n",
    "[0.0, 0.99],  # dropout_rate_1\n",
    "[0.0, 0.99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbose execution\n",
      "except! no model proportioned. \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-7874491f143c>\u001b[0m in \u001b[0;36mprediction_time\u001b[0;34m(self, batch_size, learning_rate, rho, epsilon, epochs, dropout1, dropout2, hidden_layer1, hidden_layer2, verbose)\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/BOPL/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mpredict_classes\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/BOPL/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/BOPL/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, inputs, batch_size, verbose, steps)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/BOPL/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/BOPL/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/BOPL/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m(session)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-88fe4a05fa4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Verbose execution\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobjective_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test error:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-109-7874491f143c>\u001b[0m in \u001b[0;36mprediction_time\u001b[0;34m(self, batch_size, learning_rate, rho, epsilon, epochs, dropout1, dropout2, hidden_layer1, hidden_layer2, verbose)\u001b[0m\n\u001b[1;32m     95\u001b[0m                   \u001b[0mhidden_layer1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                   \u001b[0mhidden_layer2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m                   verbose)\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-109-7874491f143c>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, batch_size, learning_rate, rho, epsilon, epochs, dropout1, dropout2, hidden_layer1, hidden_layer2, verbose)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Part 1: get the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m784\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m784\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/BOPL/lib/python3.6/site-packages/tensorflow/python/keras/datasets/mnist.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(path)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36m_read_bytes\u001b[0;34m(fp, size, error_template)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/BOPL/lib/python3.6/zipfile.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m             \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readbuffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_offset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eof\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/BOPL/lib/python3.6/zipfile.py\u001b[0m in \u001b[0;36m_read1\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_read2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compress_left\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/BOPL/lib/python3.6/zipfile.py\u001b[0m in \u001b[0;36m_read2\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    970\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compress_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_crc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/BOPL/lib/python3.6/zipfile.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Verbose execution\")\n",
    "test_error = objective_function.prediction_time(epochs = 1,verbose=1)\n",
    "print(\"Test error:\", test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n",
      "except! no model proportioned. \n",
      "10000/10000 [==============================] - 1s 52us/step\n",
      "np.mean(average_time) 1.4099397659301758\n",
      "std 1.2947044372558594\n",
      "mse 0.9154942872159311\n",
      "261.0\n",
      "np.mean(average_time) 0.09862947463989258\n",
      "std 0.0\n",
      "mse 0.0\n",
      "512.0\n",
      "np.mean(average_time) 0.09509730339050293\n",
      "std 0.0\n",
      "mse 0.0\n",
      "Test error: [1.4099397659301758, 0.09862947463989258, 0.09509730339050293]\n"
     ]
    }
   ],
   "source": [
    "test_error = []\n",
    "objective_function = mnist_mlp()\n",
    "for param in np.linspace(10,512,3):\n",
    "    print(param)\n",
    "    test_error.append(objective_function.prediction_time(learning_rate=0.001,\n",
    "                  rho=0.9,\n",
    "                  epsilon=1e-07,\n",
    "                  epochs = 3,\n",
    "                  dropout1= 0.2,\n",
    "                  dropout2= 0.2,\n",
    "                  hidden_layer1=param,\n",
    "                  hidden_layer2=param))\n",
    "print(\"Test error:\", test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning rate = [0.11988760471343994, 0.11364244173716258, 0.10597020918661887]\n",
    "dropout rate = [0.1472965326309204, 0.16162686901646214, 0.1681982852794506]\n",
    "both drop rate = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.001 , 0.5005, 1.    ])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0.001,1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 6.,  6.,  4., 11., 17., 10., 18., 17.,  7.,  4.]),\n",
       " array([0.9734 , 0.97413, 0.97486, 0.97559, 0.97632, 0.97705, 0.97778,\n",
       "        0.97851, 0.97924, 0.97997, 0.9807 ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(test_error, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0017371528430164059"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4e-06"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.002**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gym'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-3dcdd7cd0129>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CartPole-v0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi_episode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gym'"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "for i_episode in range(20):\n",
    "    observation = env.reset()\n",
    "    for t in range(100):\n",
    "        env.render()\n",
    "        print(observation)\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "            break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "const_kg",
   "language": "python",
   "name": "const_kg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
